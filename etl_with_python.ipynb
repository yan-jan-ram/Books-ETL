{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d58a0dd8-df9f-408c-bbb4-c56ae0e910c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# ETL Pipeline: Books Dataset → MySQL (books_db)\n",
    "# Author: Janaki Ram\n",
    "# Description: End-to-end ETL with structured logging and clean transformations\n",
    "# =========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ffced83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import getpass\n",
    "import urllib.parse\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfeea566-5642-4ab5-bad5-c5f4e931efab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter MySQL Workbench password:  ········\n"
     ]
    }
   ],
   "source": [
    "# configuration\n",
    "DB_USER = \"root\"\n",
    "DB_PASS = getpass.getpass(\"Enter MySQL Workbench password: \")\n",
    "encoded_pass = urllib.parse.quote_plus(DB_PASS)\n",
    "DB_HOST = \"localhost\"\n",
    "DB_NAME = \"books_db\"\n",
    "\n",
    "# file paths\n",
    "BOOKS_FILE = r\"D:\\Work\\Data Analytics\\ETL\\books_data\\csv\\books.csv\"\n",
    "RATINGS_FILE = r\"D:\\Work\\Data Analytics\\ETL\\books_data\\csv\\ratings.csv\"\n",
    "USERS_FILE = r\"D:\\Work\\Data Analytics\\ETL\\books_data\\csv\\users.csv\"\n",
    "\n",
    "# create a log file to record\n",
    "LOG_FILE = \"etl_log.txt\"\n",
    "\n",
    "# create an excel file to write the data\n",
    "STAGING_FILE = r\"D:\\Work\\Data Analytics\\ETL\\books_data\\books_staging.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eb0fe5b-d997-45d9-9bc9-f69603abd947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== ETL JOB STARTED ==========\n"
     ]
    }
   ],
   "source": [
    "# logging setup\n",
    "def log_message(message):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with open(LOG_FILE, \"a\", encoding=\"utf-8\") as log:\n",
    "        log.write(f\"[{timestamp}] {message}\\n\")\n",
    "\n",
    "    print(message)\n",
    "\n",
    "log_message(\"========== ETL JOB STARTED ==========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b421c7df-c70e-4ce7-89ea-56ef37045e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL connection established successfully\n"
     ]
    }
   ],
   "source": [
    "# database connection\n",
    "try:\n",
    "    engine = create_engine(f\"mysql+pymysql://{DB_USER}:{encoded_pass}@{DB_HOST}/{DB_NAME}\")\n",
    "    log_message(\"MySQL connection established successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    log_message(f\"Database connection failed: {e}\")\n",
    "    raise SystemExit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb49c2f-d40c-4459-98ca-4e956966b87c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTRACTING HERE...\n",
      "Loaded books.csv - 250012 rows, 8 columns\n",
      "Loaded ratings.csv - 1149780 rows, 3 columns\n",
      "Loaded users.csv - 278700 rows, 3 columns\n",
      "========== EXTRACT PHASE FINISHED ==========\n"
     ]
    }
   ],
   "source": [
    "# EXTRACT PHASE\n",
    "\n",
    "log_message(\"EXTRACTING HERE...\")\n",
    "\n",
    "def edit_columns(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(' ', '_')\n",
    "        .str.replace('-', '_')\n",
    "        .str.replace(r'[^0-9a-z_]', '', regex=True)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# function to safely read the file contents\n",
    "def read_csv_safe(filepath):\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            filepath, \n",
    "            sep=';', \n",
    "            quoting=csv.QUOTE_NONE, \n",
    "            encoding='latin-1', \n",
    "            on_bad_lines='skip',\n",
    "            engine='python'\n",
    "        )\n",
    "        df.columns = [c.strip().strip('\"') for c in df.columns] #removing the extra \" that's binding the column\n",
    "\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == object:\n",
    "                df[col] = df[col].astype(str).str.strip().str.strip('\"')\n",
    "\n",
    "        df = edit_columns(df) #editing the columns with a function\n",
    "        \n",
    "        print(f\"Loaded {os.path.basename(filepath)} - {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "        return df\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filepath}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"No data found in: {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {e}\")\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# read files\n",
    "books_raw = read_csv_safe(BOOKS_FILE)\n",
    "ratings_raw = read_csv_safe(RATINGS_FILE)\n",
    "users_raw = read_csv_safe(USERS_FILE)\n",
    "\n",
    "if books_raw.empty or ratings_raw.empty or users_raw.empty:\n",
    "    log_message(\"ETL stopped: One or more files failed to load.\")\n",
    "    raise SystemExit()\n",
    "\n",
    "log_message(\"========== EXTRACT PHASE FINISHED ==========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb9232b-5cb7-467c-9413-dfb943a815e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>image_url_s</th>\n",
       "      <th>image_url_m</th>\n",
       "      <th>image_url_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         isbn                                         book_title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0399135782                             The Kitchen God's Wife   \n",
       "\n",
       "            book_author year_of_publication                publisher  \\\n",
       "0    Mark P. O. Morford                2002  Oxford University Press   \n",
       "1  Richard Bruce Wright                2001    HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991          HarperPerennial   \n",
       "3      Gina Bari Kolata                1999     Farrar Straus Giroux   \n",
       "4               Amy Tan                1991         Putnam Pub Group   \n",
       "\n",
       "                                         image_url_s  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0399135782.0...   \n",
       "\n",
       "                                         image_url_m  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0399135782.0...   \n",
       "\n",
       "                                         image_url_l  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0399135782.0...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b35ea8f-f7b9-4b03-a599-efbb84d8bb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>book_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id        isbn book_rating\n",
       "0  276725  034545104X           0\n",
       "1  276726  0155061224           5\n",
       "2  276727  0446520802           0\n",
       "3  276729  052165615X           3\n",
       "4  276729  0521795028           6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bb3aafa-c924-4488-b358-67fd6757ccad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id                            location  age\n",
       "0       1                  nyc, new york, usa  nan\n",
       "1       2           stockton, california, usa   18\n",
       "2       3     moscow, yukon territory, russia  nan\n",
       "3       4           porto, v.n.gaia, portugal   17\n",
       "4       5  farnborough, hants, united kingdom  nan"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b694d34f-66b3-4cb0-8c43-676a63d6b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform books data\n",
    "\n",
    "def transform_books(df):\n",
    "    log_message(\"Transforming books data...\")\n",
    "\n",
    "    # clean columns\n",
    "    df['year_of_publication'] = pd.to_numeric(df['year_of_publication'], errors='coerce')\n",
    "    df.loc[(df['year_of_publication'] < 1500) | (df['year_of_publication'] > datetime.now().year), 'year_of_publication'] = pd.NA\n",
    "\n",
    "    # ensure ISBN as string\n",
    "    df['isbn'] = df['isbn'].astype(str).str.strip()\n",
    "    df = df[df['isbn'] != \"\"]\n",
    "    \n",
    "    # remove duplicates\n",
    "    before = df.shape[0]\n",
    "    df = df.drop_duplicates()\n",
    "    after = df.shape[0]\n",
    "    \n",
    "    log_message(f\"Books: removed {before - after} duplicate rows\")\n",
    "\n",
    "    log_message(f\"Books transformed: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9ff007c-19dd-4a7c-871b-be180e5d96d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform ratings data\n",
    "\n",
    "def transform_ratings(df):\n",
    "    log_message(\"Transforming ratings data...\")\n",
    "\n",
    "    # clean columns\n",
    "    df['user_id'] = pd.to_numeric(df['user_id'], errors='coerce').astype('Int64')\n",
    "    df['book_rating'] = pd.to_numeric(df['book_rating']).astype('Int64')\n",
    "\n",
    "    # Drop rows with no user_id or isbn\n",
    "    before = df.shape[0]\n",
    "    df['isbn'] = df['isbn'].astype(str).str.strip()\n",
    "    df = df.dropna(subset = ['user_id', 'isbn'])\n",
    "    after = df.shape[0]\n",
    "\n",
    "    log_message(f\"Ratings: dropped {before - after} rows with missing keys\")\n",
    "\n",
    "    # drop duplicates\n",
    "    before = df.shape[0]\n",
    "    df = df.drop_duplicates()\n",
    "    after = df.shape[0]\n",
    "\n",
    "    log_message(f\"Ratings: removed {before - after} duplicate rows\")\n",
    "\n",
    "    log_message(f\"Ratings transformed: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44553c28-8430-4314-bcce-20a783369066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform users data\n",
    "\n",
    "def transform_users(df):\n",
    "    log_message(\"Transforming users data...\")\n",
    "\n",
    "    # clean columns\n",
    "    df['user_id'] = pd.to_numeric(df['user_id'], errors='coerce').astype('Int64')\n",
    "    df['age'] = pd.to_numeric(df['age'], errors='coerce').astype('Int64')\n",
    "    df.loc[(df['age'] < 5) | (df['age'] > 100), 'age'] = pd.NA\n",
    "\n",
    "    # split location into city, state, country\n",
    "    location_split = df['location'].str.split(',', n=2, expand=True)\n",
    "    df['city'] = location_split[0].str.strip()\n",
    "    df['state'] = location_split[1].str.strip() if location_split.shape[1] > 1 else pd.NA\n",
    "    df['country'] = location_split[2].str.strip() if location_split.shape[1] > 2 else pd.NA\n",
    "\n",
    "    # drop duplicates\n",
    "    before = df.shape[0]\n",
    "    df = df.drop_duplicates()\n",
    "    after = df.shape[0]\n",
    "\n",
    "    log_message(f\"Users: removed {before - after} duplicate rows\")\n",
    "\n",
    "    log_message(f\"Users transformed: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6104287c-3f36-43e3-a99f-dd88c628b491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSFORMING HERE...\n",
      "Transforming books data...\n",
      "Books: removed 1 duplicate rows\n",
      "Books transformed: 250011 rows, 8 columns\n",
      "Transforming ratings data...\n",
      "Ratings: dropped 0 rows with missing keys\n",
      "Ratings: removed 0 duplicate rows\n",
      "Ratings transformed: 1149780 rows, 3 columns\n",
      "Transforming users data...\n",
      "Users: removed 0 duplicate rows\n",
      "Users transformed: 278700 rows, 6 columns\n",
      "Creating Excel staging file...\n",
      "Staging Excel created: D:\\Work\\Data Analytics\\ETL\\books_data\\books_staging.xlsx\n",
      "========== TRANSFORM PHASE FINISHED ==========\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORM PHASE\n",
    "\n",
    "log_message(\"TRANSFORMING HERE...\")\n",
    "\n",
    "books_clean = transform_books(books_raw)\n",
    "ratings_clean = transform_ratings(ratings_raw)\n",
    "users_clean = transform_users(users_raw)\n",
    "\n",
    "# staging\n",
    "MAX_EXCEL_ROWS = 1_048_575  # Excel row limit\n",
    "\n",
    "def write_df_with_row_limit(df, writer, base_sheet_name):\n",
    "    n = len(df)\n",
    "    if n <= MAX_EXCEL_ROWS:\n",
    "        df.to_excel(writer, sheet_name=base_sheet_name, index=False)\n",
    "    else:\n",
    "        part = 1\n",
    "        start = 0\n",
    "        while start < n:\n",
    "            end = min(start + MAX_EXCEL_ROWS, n)\n",
    "            sheet = f\"{base_sheet_name}_{part}\"\n",
    "            df.iloc[start:end].to_excel(writer, sheet_name=sheet, index=False)\n",
    "            start = end\n",
    "            part += 1\n",
    "\n",
    "log_message(\"Creating Excel staging file...\")\n",
    "\n",
    "with pd.ExcelWriter(STAGING_FILE, engine='openpyxl') as writer:\n",
    "    write_df_with_row_limit(books_clean, writer, 'Books')\n",
    "    write_df_with_row_limit(ratings_clean, writer, 'Ratings')\n",
    "    write_df_with_row_limit(users_clean, writer, 'Users')\n",
    "\n",
    "log_message(f\"Staging Excel created: {STAGING_FILE}\")\n",
    "log_message(\"========== TRANSFORM PHASE FINISHED ==========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c002bc79-0510-449d-ba1f-96fbab2ab01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openpyxl import load_workbook\n",
    "\n",
    "# def write_head_summary(excel_file):\n",
    "#     wb = load_workbook(excel_file)\n",
    "#     writer = pd.ExcelWriter(excel_file, engine='openpyxl')\n",
    "#     writer.book = wb\n",
    "#     writer.sheets = {ws.title: ws for ws in wb.worksheets}\n",
    "\n",
    "#     # read sheets\n",
    "#     books = pd.read_excel(excel_file, sheet_name=\"Books\")\n",
    "#     ratings = pd.read_excel(excel_file, sheet_name=\"Ratings\")\n",
    "#     users = pd.read_excel(excel_file, sheet_name=\"Users\")\n",
    "\n",
    "#     start_row = 0\n",
    "\n",
    "#     # write summary sheet\n",
    "#     summary_sheet = \"Summary\"\n",
    "\n",
    "#     df_list = [\n",
    "#         (\"Books\", books.head()),\n",
    "#         (\"Ratings\", ratings.head()),\n",
    "#         (\"Users\", users.head())\n",
    "#     ]\n",
    "\n",
    "#     for name, df in df_list:\n",
    "#         # Title\n",
    "#         writer.book.create_sheet(summary_sheet) if summary_sheet not in writer.book.sheetnames else None\n",
    "#         ws = writer.book[summary_sheet]\n",
    "#         ws.cell(row=start_row + 1, column=1, value=f\"=== {name} (head) ===\")\n",
    "\n",
    "#         # Write df below title\n",
    "#         df.to_excel(writer, sheet_name=summary_sheet, startrow=start_row + 2, index=False)\n",
    "\n",
    "#         # Move pointer for next block (+2 for spacing)\n",
    "#         start_row += len(df) + 4\n",
    "\n",
    "#     writer.save()\n",
    "#     writer.close()\n",
    "\n",
    "# write_head_summary(STAGING_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16d4cb21-4b89-4b7f-9931-14bddb091eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING HERE...\n",
      "Loaded sheet 'books' -> 250011 rows\n",
      "Loaded sheet 'ratings' -> 1149780 rows\n",
      "Loaded sheet 'users' -> 278700 rows\n",
      "All sheets loaded successfully.\n",
      "========== LOAD PHASE FINISHED ==========\n",
      "========== ETL JOB COMPLETED ==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LOAD PHASE\n",
    "\n",
    "log_message(\"LOADING HERE...\")\n",
    "\n",
    "xls = pd.ExcelFile(STAGING_FILE, engine='openpyxl')\n",
    "\n",
    "books_final = pd.read_excel(xls, sheet_name='Books')\n",
    "users_final = pd.read_excel(xls, sheet_name='Users')\n",
    "\n",
    "rating_sheets = [s for s in xls.sheet_names if s.startswith(\"Ratings\")]\n",
    "ratings_final = pd.concat([pd.read_excel(xls, s) for s in rating_sheets], ignore_index=True)\n",
    "\n",
    "def load_to_mysql(df, sheet):\n",
    "    try:\n",
    "        df.to_sql(name=sheet, con=engine, if_exists='replace', index=False)\n",
    "        log_message(f\"Loaded sheet '{sheet}' -> {df.shape[0]} rows\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Failed to load '{sheet}': {e}\")\n",
    "\n",
    "\n",
    "load_to_mysql(books_final, \"books\")\n",
    "load_to_mysql(ratings_final, \"ratings\")\n",
    "load_to_mysql(users_final, \"users\")\n",
    "\n",
    "log_message(\"All sheets loaded successfully.\")\n",
    "log_message(\"========== LOAD PHASE FINISHED ==========\")\n",
    "log_message(\"========== ETL JOB COMPLETED ==========\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dec7ff-36dd-43e7-a379-4b438c6303e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
